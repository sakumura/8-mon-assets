"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼éŸ³å£°ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ8-mon-assetsç‰ˆï¼‰
VOICEVOXã‚’ä½¿ç”¨ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ä¸€äººèª­ã¿å½¢å¼ã§éŸ³å£°åŒ–

éŸ³å£°: VOICEVOX:å››å›½ã‚ãŸã‚“
- VOICEVOX: https://voicevox.hiroshiba.jp/
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ©ç”¨è¦ç´„: https://zunko.jp/con_ongen_kiyaku.html
"""
import os
import io
import re
import sys
from datetime import datetime
from pathlib import Path
import argparse

import requests
from pydub import AudioSegment

# VOICEVOXè¨­å®š
VOICEVOX_URL = os.environ.get("VOICEVOX_URL", "http://localhost:50021")
SPEAKER_ID = 2  # å››å›½ã‚ãŸã‚“ï¼ˆãƒãƒ¼ãƒãƒ«ï¼‰


def synthesize_voicevox(text: str, speaker_id: int = SPEAKER_ID) -> bytes:
    """VOICEVOXã§éŸ³å£°åˆæˆ"""
    query_resp = requests.post(
        f"{VOICEVOX_URL}/audio_query",
        params={"text": text, "speaker": speaker_id},
        timeout=30
    )
    query_resp.raise_for_status()
    query = query_resp.json()

    synth_resp = requests.post(
        f"{VOICEVOX_URL}/synthesis",
        params={"speaker": speaker_id},
        json=query,
        timeout=60
    )
    synth_resp.raise_for_status()
    return synth_resp.content


def normalize_for_tts(text: str) -> str:
    """TTSç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆèª­ã¿æ›¿ãˆï¼‰"""
    replacements = {
        # è‹±èªç•¥èª
        "BTC": "ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³",
        "NASDAQ": "ãƒŠã‚¹ãƒ€ãƒƒã‚¯",
        "USD/JPY": "ãƒ‰ãƒ«å††",
        "GOLD": "ã‚´ãƒ¼ãƒ«ãƒ‰",
        "VIX": "ãƒ“ãƒƒã‚¯ã‚¹",
        "ETF": "ã‚¤ãƒ¼ãƒ†ã‚£ãƒ¼ã‚¨ãƒ•",
        "ATM IV": "ã‚¨ãƒ¼ãƒ†ã‚£ãƒ¼ã‚¨ãƒ  ã‚¢ã‚¤ãƒ–ã‚¤",
        "IV": "ã‚¢ã‚¤ãƒ–ã‚¤",
        "HV": "ã‚¨ã‚¤ãƒãƒ–ã‚¤",
        "1570": "ã‚¤ãƒã‚´ãƒ¼ãƒŠãƒŠã‚¼ãƒ­",
        "N5": "ã‚¨ãƒŒãƒ•ã‚¡ã‚¤ãƒ–",
        "N220": "ã‚¨ãƒŒãƒ‹ãƒ¼ãƒ‹ãƒ¼ã‚¼ãƒ­",
        # æ—¥æœ¬èªèª­ã¿
        "æ—¥çµŒ225": "ãƒ‹ãƒƒã‚±ã‚¤ãƒ‹ãƒ¼ãƒ‹ãƒ¼ã‚´",
        "è‡¥é¾": "ãŒã‚Šã‚‡ã†",
        "å€¤åµ©": "ã­ãŒã•",
        "ä¿¡ç”¨å€ç‡": "ã—ã‚“ã‚ˆã†ã°ã„ã‚Šã¤",
        "è²¸æ ªé‡‘åˆ©": "ã‹ã—ã‹ã¶ãã‚“ã‚Š",
        "å»ºç‰": "ãŸã¦ãã‚‡ã",
        "å¯„ä¸ç‡": "ãã‚ˆã‚Šã¤",
        # è¨˜å·
        "â”": "", "â– ": "", "â–¼": "", "ã€": "", "ã€‘": "",
        "ğŸ“Š": "", "ğŸ“…": "",
        "â†’": "ã€", "â€¦": "ã€", "|": "ã€", "â€»": "ã€ãªãŠã€",
    }
    for original, reading in replacements.items():
        text = text.replace(original, reading)
    text = re.sub(r'[\U0001F300-\U0001F9FF]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def parse_newsletter_txt(txt_path: Path) -> dict:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼TXTã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¾æ›¸ã«åˆ†è§£"""
    content = txt_path.read_text(encoding="utf-8")
    filename = txt_path.stem

    if filename.startswith("night_"):
        version = "night"
        date_str = filename.replace("night_", "")
    elif filename.startswith("morning_"):
        version = "morning"
        date_str = filename.replace("morning_", "")
    elif filename.startswith("lunch_"):
        version = "lunch"
        date_str = filename.replace("lunch_", "")
    else:
        version = "unknown"
        date_str = ""

    sections = {}
    current_section = "header"
    current_content = []

    for line in content.split("\n"):
        if line.startswith("â– "):
            if current_content:
                sections[current_section] = "\n".join(current_content).strip()
            match = re.match(r"â– \s*(\d+)\.\s*(.+)", line)
            if match:
                current_section = f"{match.group(1)}_{match.group(2).strip()}"
            else:
                current_section = line.replace("â– ", "").strip()
            current_content = []
        else:
            current_content.append(line)

    if current_content:
        sections[current_section] = "\n".join(current_content).strip()

    return {"version": version, "date": date_str, "sections": sections, "raw_content": content}


def newsletter_to_script_night(parsed: dict) -> str:
    """å¤œç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ä¸€äººèª­ã¿åŸç¨¿ã«å¤‰æ›"""
    sections = parsed["sections"]
    date_str = parsed["date"]

    try:
        dt = datetime.strptime(date_str, "%Y-%m-%d")
        weekdays = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
        date_readable = f"{dt.month}æœˆ{dt.day}æ—¥ã€{weekdays[dt.weekday()]}æ›œæ—¥"
    except:
        date_readable = date_str

    script_parts = [f"ã“ã‚“ã°ã‚“ã¯ã€‚å…«é–€éç”²ãƒŠã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚æœ¬æ—¥ã¯{date_readable}ã§ã™ã€‚"]

    # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†
    if "1_æœ¬æ—¥ã®å¸‚å ´ç·æ‹¬" in sections:
        content = sections["1_æœ¬æ—¥ã®å¸‚å ´ç·æ‹¬"]
        regime_match = re.search(r"ã€ãƒ¬ã‚¸ãƒ¼ãƒ ã€‘(.+?)(?:\n|$)", content)
        regime = regime_match.group(1).strip() if regime_match else ""
        narrative_match = re.search(r"ã€å¸‚å ´ãƒŠãƒ©ãƒ†ã‚£ãƒ–ã€‘\n(.+?)(?:\n\n|$)", content, re.DOTALL)
        narrative = narrative_match.group(1).strip() if narrative_match else ""
        script_parts.append(f"æœ¬æ—¥ã®å¸‚å ´ç·æ‹¬ã§ã™ã€‚{regime} {narrative}")

    if "2_ä¿¡ç”¨å€ç‡ï¼ˆ1570 æ—¥çµŒãƒ¬ãƒETFï¼‰" in sections:
        content = sections["2_ä¿¡ç”¨å€ç‡ï¼ˆ1570 æ—¥çµŒãƒ¬ãƒETFï¼‰"]
        lines = [l.strip() for l in content.split("\n") if l.strip() and not l.startswith("â€»")][:4]
        script_parts.append(f"ç¶šã„ã¦ã€1570æ—¥çµŒãƒ¬ãƒã‚¤ãƒ¼ãƒ†ã‚£ãƒ¼ã‚¨ãƒ•ã®ä¿¡ç”¨å€ç‡ã§ã™ã€‚{' '.join(lines)}")

    if "3_éœ€çµ¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆ1570 æ—¥çµŒãƒ¬ãƒETFï¼‰" in sections:
        content = sections["3_éœ€çµ¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆ1570 æ—¥çµŒãƒ¬ãƒETFï¼‰"]
        lines = [l.strip() for l in content.split("\n") if l.strip()][:5]
        script_parts.append(f"éœ€çµ¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚{' '.join(lines)}")

    if "4_å€¤åµ©æ ªå½±éŸ¿ï¼ˆN5å¯„ä¸ç‡ï¼‰" in sections:
        content = sections["4_å€¤åµ©æ ªå½±éŸ¿ï¼ˆN5å¯„ä¸ç‡ï¼‰"]
        lines = [l.strip() for l in content.split("\n") if l.strip() and l.startswith("-")][:2]
        script_parts.append(f"å€¤åµ©æ ªã®å½±éŸ¿åº¦ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚{' '.join(lines)}")

    if "5_ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´" in sections:
        content = sections["5_ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´"]
        lines = [l.strip() for l in content.split("\n") if l.strip() and l.startswith("-")][:5]
        script_parts.append(f"ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¸‚å ´ã®çŠ¶æ³ã§ã™ã€‚{' '.join(lines)}")

    if "6_å¤–å›½äººæŠ•è³‡å®¶å‹•å‘" in sections:
        content = sections["6_å¤–å›½äººæŠ•è³‡å®¶å‹•å‘"]
        lines = [l.strip() for l in content.split("\n") if l.strip() and l.startswith("-")][:4]
        script_parts.append(f"å¤–å›½äººæŠ•è³‡å®¶ã®å‹•å‘ã‚’ç¢ºèªã—ã¾ã™ã€‚{' '.join(lines)}")

    if "7_ã‚°ãƒ­ãƒ¼ãƒãƒ«ç›¸é–¢" in sections:
        content = sections["7_ã‚°ãƒ­ãƒ¼ãƒãƒ«ç›¸é–¢"]
        lines = [l.strip() for l in content.split("\n") if l.strip() and l.startswith("- æ—¥çµŒ")]
        script_parts.append(f"ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ã¨ã®ç›¸é–¢ã‚’è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚{' '.join(lines)}")

    if "8_æœ¬æ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹" in sections:
        content = sections["8_æœ¬æ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹"]
        news_items = re.findall(r"(\d+)\.\s*(.+?)(?:\n|$)", content)
        if news_items:
            script_parts.append("æœ¬æ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠä¼ãˆã—ã¾ã™ã€‚")
            for num, headline in news_items[:3]:
                script_parts.append(f"{num}ä»¶ç›®ã€‚{headline}")

    if "9_è‡¥é¾ç·æ‹¬" in sections:
        content = sections["9_è‡¥é¾ç·æ‹¬"]
        quote_match = re.search(r"è«¸è‘›äº®æ›°ã[â€•ãƒ¼]\s*(.+?)(?:ãŸã ã—ã€ã“ã‚Œã¯|â”|$)", content, re.DOTALL)
        if quote_match:
            quote = quote_match.group(1).strip()
            quote = re.sub(r"[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã«ã€", "ã€‚", quote)
            script_parts.append(f"æœ€å¾Œã«ã€è‡¥é¾ã‹ã‚‰ã®ç·æ‹¬ã§ã™ã€‚{quote}")

    script_parts.append("ä»¥ä¸Šã€å…«é–€éç”²ãƒŠã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆã§ã—ãŸã€‚æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡åŠ©è¨€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚")
    return "\n\n".join(script_parts)


def newsletter_to_script_morning(parsed: dict) -> str:
    """æœç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ä¸€äººèª­ã¿åŸç¨¿ã«å¤‰æ›"""
    sections = parsed["sections"]
    date_str = parsed["date"]

    try:
        dt = datetime.strptime(date_str, "%Y-%m-%d")
        weekdays = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
        date_readable = f"{dt.month}æœˆ{dt.day}æ—¥ã€{weekdays[dt.weekday()]}æ›œæ—¥"
    except:
        date_readable = date_str

    script_parts = [f"ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚å…«é–€éç”²ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ–ãƒªãƒ¼ãƒ•ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚æœ¬æ—¥ã¯{date_readable}ã§ã™ã€‚"]

    for section_key, content in sections.items():
        if section_key == "header":
            continue
        section_name = section_key.split("_", 1)[-1] if "_" in section_key else section_key
        lines = [l.strip() for l in content.split("\n") if l.strip()][:5]
        script_parts.append(f"{section_name}ã§ã™ã€‚{' '.join(lines)}")

    script_parts.append("ä»¥ä¸Šã€å…«é–€éç”²ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ–ãƒªãƒ¼ãƒ•ã§ã—ãŸã€‚æœ¬æ—¥ã‚‚è‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’ã€‚")
    return "\n\n".join(script_parts)


def newsletter_to_script_lunch(parsed: dict) -> str:
    """æ˜¼ç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ä¸€äººèª­ã¿åŸç¨¿ã«å¤‰æ›"""
    content = parsed["raw_content"]
    date_str = parsed["date"]

    try:
        dt = datetime.strptime(date_str, "%Y-%m-%d")
        weekdays = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
        date_readable = f"{dt.month}æœˆ{dt.day}æ—¥ã€{weekdays[dt.weekday()]}æ›œæ—¥"
    except:
        date_readable = date_str

    script_parts = [f"ã“ã‚“ã«ã¡ã¯ã€‚å…«é–€éç”²ãƒ©ãƒ³ãƒãƒ¬ãƒãƒ¼ãƒˆã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚æœ¬æ—¥ã¯{date_readable}ã§ã™ã€‚æœ¬æ—¥ã®æ´»æ³éŠ˜æŸ„ã‚’åˆ†æã—ã¦ã„ãã¾ã™ã€‚"]

    stock_matches = re.findall(r"ã€(\d+)ä½ã€‘\s*(\d+)\s+(.+?)ï¼ˆ([+-]?\d+\.?\d*)%ï¼‰", content)
    for rank, code, name, change in stock_matches[:5]:
        script_parts.append(f"{rank}ä½ã¯{name}ã€å‰æ—¥æ¯”{change}ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã§ã™ã€‚")

    mashoku_match = re.search(r"é¦¬è¬–ã®æ˜¼é¤‰ã‚³ãƒ¡ãƒ³ãƒˆ[â”â”]*\n(.+?)(?:====|$)", content, re.DOTALL)
    if mashoku_match:
        comment = mashoku_match.group(1).strip()[:200]
        script_parts.append(f"é¦¬è¬–ã‹ã‚‰ã®ã‚³ãƒ¡ãƒ³ãƒˆã§ã™ã€‚{comment}")

    script_parts.append("ä»¥ä¸Šã€å…«é–€éç”²ãƒ©ãƒ³ãƒãƒ¬ãƒãƒ¼ãƒˆã§ã—ãŸã€‚å¾Œå ´ã‚‚è‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’ã€‚")
    return "\n\n".join(script_parts)


def newsletter_to_script(parsed: dict) -> str:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã‚’ä¸€äººèª­ã¿åŸç¨¿ã«å¤‰æ›"""
    version = parsed["version"]
    if version == "night":
        return newsletter_to_script_night(parsed)
    elif version == "morning":
        return newsletter_to_script_morning(parsed)
    elif version == "lunch":
        return newsletter_to_script_lunch(parsed)
    return parsed["raw_content"]


def generate_audio_from_script(script: str, output_path: Path, pause_ms: int = 500):
    """åŸç¨¿ã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆ"""
    audio_segments = []
    paragraphs = [p.strip() for p in script.split("\n\n") if p.strip()]

    for i, paragraph in enumerate(paragraphs):
        sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', paragraph)
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            text_clean = normalize_for_tts(sentence)
            if not text_clean:
                continue

            if len(text_clean) > 100:
                parts = text_clean.split("ã€")
                for j, part in enumerate(parts):
                    if not part.strip():
                        continue
                    part_text = part.strip() + ("ã€" if j < len(parts) - 1 else "")
                    print(f"    [{i+1}] {part_text[:50]}...")
                    wav_bytes = synthesize_voicevox(part_text)
                    audio_segments.append(AudioSegment.from_wav(io.BytesIO(wav_bytes)))
                    audio_segments.append(AudioSegment.silent(duration=150))
            else:
                print(f"    [{i+1}] {text_clean[:50]}...")
                wav_bytes = synthesize_voicevox(text_clean)
                audio_segments.append(AudioSegment.from_wav(io.BytesIO(wav_bytes)))
                audio_segments.append(AudioSegment.silent(duration=300))

        audio_segments.append(AudioSegment.silent(duration=pause_ms))

    combined = AudioSegment.empty()
    for seg in audio_segments:
        combined += seg

    output_path.parent.mkdir(parents=True, exist_ok=True)
    combined.export(output_path, format="mp3", bitrate="192k")
    return output_path


def main():
    parser = argparse.ArgumentParser(description='Generate audio from newsletter')
    parser.add_argument('input', nargs='+', help='Input newsletter TXT file path(s)')
    parser.add_argument('--output-dir', '-o', type=str, default='output/newsletter',
                        help='Output directory for MP3 files')
    args = parser.parse_args()

    # VOICEVOXæ¥ç¶šç¢ºèª
    try:
        version_resp = requests.get(f"{VOICEVOX_URL}/version", timeout=5)
        print(f"VOICEVOX version: {version_resp.text}")
    except Exception as e:
        print(f"ERROR: VOICEVOX connection failed: {e}")
        sys.exit(1)

    output_dir = Path(args.output_dir)

    for input_file in args.input:
        txt_path = Path(input_file)
        if not txt_path.exists():
            print(f"ERROR: File not found: {txt_path}")
            continue

        print(f"\n=== Processing: {txt_path.name} ===")
        parsed = parse_newsletter_txt(txt_path)
        print(f"  Version: {parsed['version']}, Date: {parsed['date']}")

        script = newsletter_to_script(parsed)
        print(f"  Script length: {len(script)} chars")

        output_path = output_dir / f"{parsed['version']}_{parsed['date']}.mp3"
        print(f"  Generating audio...")
        generate_audio_from_script(script, output_path)

        file_size = output_path.stat().st_size
        print(f"  Output: {output_path} ({file_size:,} bytes)")

    print("\n=== å®Œäº† ===")


if __name__ == "__main__":
    main()
